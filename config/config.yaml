training:
  batch_size: 32
  learning_rate: 0.001
  epochs: 10

models:
  speaker_encoder:
    in_dim: 80
    hidden_dim: 256
    out_dim: 256

data:
  dataset:
    name: "LibriSpeech"
    path: "./datasets"
  dataloader:
    num_workers: 4
    distributed: False
    pin_memory: True
    drop_last: False
  mel_transform:
    sample_rate: 16000
    filter_length: 1280
    win_length: 1280
    hop_length: 320
    n_mel_channels: 80
    f_min: 0
    f_max: 8000
