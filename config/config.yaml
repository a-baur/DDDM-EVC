training:
  batch_size: 32
  learning_rate: 0.001
  epochs: 10

dataset:
  name: "LibriSpeech"
  path: "../datasets"

models:
  speaker_encoder:
    in_dim: 80
    hidden_dim: 256
    out_dim: 256

dataloader:
  num_workers: 4
  distributed: False
  pin_memory: True
  drop_last: False
