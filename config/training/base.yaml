seed: 42
batch_size: 32
epochs: 100
segment_size: 38000
learning_rate: 5e-5
lr_decay: 0.999875
betas: [0.8, 0.99]
eps: 1e-9
use_fp16_scaling: false  # gradient scaling
diff_loss_coef: 1.0
rec_loss_coef: 1.0
log_interval: 1
eval_interval: 20
save_interval: 50
output_dir: ${hydra:runtime.cwd}/${hydra:run.dir}
eval_n_batches: 100  # Number of batches to eval during training
